{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "name": "Example.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "id": "UMwfnZQ48f3n",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1628675770654,
     "user_tz": -60,
     "elapsed": 523,
     "user": {
      "displayName": "Keith Bines",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh-1rHYFN7Yxp7RK0dmcaDIhb3bISQHVPcOLlyYAA=s64",
      "userId": "04847342589282886972"
     }
    }
   },
   "source": [
    "import gym\n",
    "import PortfolioAllocationGym\n",
    "import numpy as np\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "Au1mKD618f3w",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1628675850134,
     "user_tz": -60,
     "elapsed": 9939,
     "user": {
      "displayName": "Keith Bines",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh-1rHYFN7Yxp7RK0dmcaDIhb3bISQHVPcOLlyYAA=s64",
      "userId": "04847342589282886972"
     }
    }
   },
   "source": [
    "env_kwargs = {'filename':'sp500.csv',\n",
    "    'date_from':'2008-01-01',\n",
    "    'date_to':'2017-12-31',\n",
    "    'investment':1000000,\n",
    "    'risk_free_rate': 0.5, # approx US Treasury Note return\n",
    "    'sample_size':100,\n",
    "    'random_sample':False,\n",
    "    'reward_function':'portfolio_value'}\n",
    "\n",
    "train_env = gym.make('PortfolioAllocation-v0', **env_kwargs)"
   ],
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kbine\\anaconda3\\envs\\PortfolioAllocationRL\\lib\\site-packages\\stable_baselines3\\common\\env_checker.py:26: UserWarning: It seems that your observation  is an image but the `dtype` of your observation_space is not `np.uint8`. If your observation is not an image, we recommend you to flatten the observation to have only a 1D vector\n",
      "  warnings.warn(\n",
      "C:\\Users\\kbine\\anaconda3\\envs\\PortfolioAllocationRL\\lib\\site-packages\\stable_baselines3\\common\\env_checker.py:34: UserWarning: It seems that your observation space  is an image but the upper and lower bounds are not in [0, 255]. Because the CNN policy normalize automatically the observation you may encounter issue if the values are not in that range.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kbine\\anaconda3\\envs\\PortfolioAllocationRL\\lib\\site-packages\\stable_baselines3\\common\\preprocessing.py:23: UserWarning: Treating image space as channels-last, while second dimension was smallest of the three.\n",
      "  warnings.warn(\"Treating image space as channels-last, while second dimension was smallest of the three.\")\n",
      "C:\\Users\\kbine\\anaconda3\\envs\\PortfolioAllocationRL\\lib\\site-packages\\stable_baselines3\\common\\env_checker.py:47: UserWarning: The minimal resolution for an image is 36x36 for the default `CnnPolicy`. You might need to use a custom feature extractor cf. https://stable-baselines3.readthedocs.io/en/master/guide/custom_policy.html\n",
      "  warnings.warn(\n",
      "C:\\Users\\kbine\\anaconda3\\envs\\PortfolioAllocationRL\\lib\\site-packages\\stable_baselines3\\common\\env_checker.py:272: UserWarning: We recommend you to use a symmetric and normalized Box action space (range=[-1, 1]) cf https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "check_env(train_env)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "venv, obs = train_env.get_sb_env()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "4cLMqQlb8f30"
   },
   "source": [
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3.a2c import MlpPolicy"
   ],
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "pmyfRQxy8f33"
   },
   "source": [
    "import torch\n",
    "\n",
    "model_kwargs =   {'gamma': 0.9999,\n",
    "    'normalize_advantage': False,\n",
    "    'max_grad_norm': 0.7,\n",
    "    'use_rms_prop': False,\n",
    "    'gae_lambda': 0.92,\n",
    "    'n_steps': 10,\n",
    "    'learning_rate': 0.0038610316815332825,\n",
    "    'ent_coef': 0.012292116134058367,\n",
    "    'vf_coef': 0.7960524189522955,\n",
    "    'policy_kwargs': dict(\n",
    "        log_std_init=-3.353286611055509,\n",
    "        ortho_init= False,\n",
    "        activation_fn=torch.nn.modules.activation.ReLU,\n",
    "        net_arch=[dict(pi=[64, 64, 64], vf=[64, 64, 64])])\n",
    "    }\n",
    "a2c_model = A2C(policy = MlpPolicy,\n",
    "                env = venv,\n",
    "                **model_kwargs)\n"
   ],
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "1QwoU6Fu8f36"
   },
   "source": [
    "from PortfolioAllocationGym.callbacks import TensorBoardCallback as tbc\n",
    "from datetime import datetime"
   ],
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2516                 reward: 3393953.530                 sharpe: 0.395                  psr: 0.000                  cum. rtns: 239.395                 portf val: 3,393,953.53\n",
      "day: 2516                 reward: 3361192.112                 sharpe: 0.399                  psr: 0.000                  cum. rtns: 236.119                 portf val: 3,361,192.11\n",
      "day: 2516                 reward: 3355335.076                 sharpe: 0.399                  psr: 0.000                  cum. rtns: 235.534                 portf val: 3,355,335.08\n",
      "day: 2516                 reward: 3350199.976                 sharpe: 0.399                  psr: 0.000                  cum. rtns: 235.020                 portf val: 3,350,199.98\n",
      "day: 2516                 reward: 3347830.353                 sharpe: 0.399                  psr: 0.000                  cum. rtns: 234.783                 portf val: 3,347,830.35\n",
      "mean_reward:73.04 +/- 27.95\n"
     ]
    }
   ],
   "source": [
    "# Random Agent, before training\n",
    "mean_reward, std_reward = evaluate_policy(a2c_model, venv, n_eval_episodes=5)\n",
    "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "rC1P65268f3-"
   },
   "source": [
    "#total_timesteps = 2 * (len(train_env.venv.venv.envs[0].data.date.unique())-1)\n",
    "total_timesteps = 10 * (len(train_env.data.date.unique())-1)\n",
    "trained_a2c_model= a2c_model.learn(total_timesteps=total_timesteps,\n",
    "                                   tb_log_name='A2C'+datetime.now().strftime(\"%H-%M\"))"
   ],
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2516                 reward: 2975263.327                 sharpe: 0.392                  psr: 0.000                  cum. rtns: 197.526                 portf val: 2,975,263.33\n",
      "day: 2516                 reward: 2845850.310                 sharpe: 0.340                  psr: 0.000                  cum. rtns: 184.585                 portf val: 2,845,850.31\n",
      "day: 2516                 reward: 2584910.383                 sharpe: 0.298                  psr: 0.000                  cum. rtns: 158.491                 portf val: 2,584,910.38\n",
      "day: 2516                 reward: 2805226.133                 sharpe: 0.379                  psr: 0.000                  cum. rtns: 180.523                 portf val: 2,805,226.13\n",
      "day: 2516                 reward: 2456507.539                 sharpe: 0.284                  psr: 0.000                  cum. rtns: 145.651                 portf val: 2,456,507.54\n",
      "day: 2516                 reward: 2201985.942                 sharpe: 0.287                  psr: 0.000                  cum. rtns: 120.199                 portf val: 2,201,985.94\n",
      "day: 2516                 reward: 2220603.142                 sharpe: 0.276                  psr: 0.000                  cum. rtns: 122.060                 portf val: 2,220,603.14\n",
      "day: 2516                 reward: 2236747.319                 sharpe: 0.253                  psr: 0.000                  cum. rtns: 123.675                 portf val: 2,236,747.32\n",
      "day: 2516                 reward: 2275971.613                 sharpe: 0.294                  psr: 0.000                  cum. rtns: 127.597                 portf val: 2,275,971.61\n",
      "day: 2516                 reward: 2423179.847                 sharpe: 0.279                  psr: 0.000                  cum. rtns: 142.318                 portf val: 2,423,179.85\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2516                 reward: 2489789.039                 sharpe: 0.276                  psr: 0.000                  cum. rtns: 148.979                 portf val: 2,489,789.04\n",
      "day: 2516                 reward: 2489401.154                 sharpe: 0.276                  psr: 0.000                  cum. rtns: 148.940                 portf val: 2,489,401.15\n",
      "day: 2516                 reward: 2489093.883                 sharpe: 0.276                  psr: 0.000                  cum. rtns: 148.909                 portf val: 2,489,093.88\n",
      "day: 2516                 reward: 2488820.449                 sharpe: 0.276                  psr: 0.000                  cum. rtns: 148.882                 portf val: 2,488,820.45\n",
      "day: 2516                 reward: 2488584.486                 sharpe: 0.276                  psr: 0.000                  cum. rtns: 148.858                 portf val: 2,488,584.49\n",
      "mean_reward:57.55 +/- 0.54\n"
     ]
    }
   ],
   "source": [
    "mean_reward, std_reward = evaluate_policy(trained_a2c_model, venv, n_eval_episodes=5)\n",
    "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "eval_kwargs = {'filename':'sp500.csv',\n",
    "    'date_from':'2018-01-01',\n",
    "    'date_to':'2020-12-31',\n",
    "    'investment':1000000,\n",
    "    'risk_free_rate': 0.5,\n",
    "    'reward_function':'daily_returns'}\n",
    "\n",
    "eval_env =  Monitor(gym.make('PortfolioAllocation-v0', **eval_kwargs))\n",
    "\n",
    "mean_reward, std_reward = evaluate_policy(trained_a2c_model, eval_env, n_eval_episodes=10)\n",
    "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "trained_a2c_model.save('sp500_08_17_opt_49')\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}