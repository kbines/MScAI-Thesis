{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "name": "Example.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "id": "UMwfnZQ48f3n",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1628675770654,
     "user_tz": -60,
     "elapsed": 523,
     "user": {
      "displayName": "Keith Bines",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh-1rHYFN7Yxp7RK0dmcaDIhb3bISQHVPcOLlyYAA=s64",
      "userId": "04847342589282886972"
     }
    }
   },
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore',\n",
    "                        category=DeprecationWarning,\n",
    "                        module='stable_baselines')\n",
    "warnings.filterwarnings(action='ignore',\n",
    "                        category=UserWarning,\n",
    "                        module='stable_baselines')\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module='tensorflow')\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module='tensorboard')\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='gym')\n",
    "\n",
    "import gym\n",
    "import PortfolioAllocationGym\n",
    "import numpy as np\n",
    "from stable_baselines import A2C\n",
    "from stable_baselines.common.policies import MlpLnLstmPolicy #, MlpPolicy, MlpLstmPolicy\n",
    "from stable_baselines.common.evaluation import evaluate_policy\n",
    "from stable_baselines.common.env_checker import check_env\n",
    "from stable_baselines.bench import Monitor\n",
    "from tensorflow import nn as nn\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "from datetime import datetime"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "Au1mKD618f3w",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1628675850134,
     "user_tz": -60,
     "elapsed": 9939,
     "user": {
      "displayName": "Keith Bines",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh-1rHYFN7Yxp7RK0dmcaDIhb3bISQHVPcOLlyYAA=s64",
      "userId": "04847342589282886972"
     }
    }
   },
   "source": [
    "observations = ['daily_returns', 'ema_50', 'ema_200', 'bb_bbm', 'bb_bbh', 'bb_bbl','bb_bbhi', 'bb_bbli', 'stoch', 'stoch_signal', 'macd','macd_signal', 'obv']\n",
    "env_kwargs = {'filename':'sp500.csv',\n",
    "    'date_from':'2008-01-01',\n",
    "    'date_to':'2017-12-31',\n",
    "    'investment':1000000,\n",
    "    'risk_free_rate': 0.5, # approx US Treasury Note return\n",
    "    'sample_size':10,\n",
    "    'random_sample':True,\n",
    "    'observations' : observations,\n",
    "    'save_info' : True,\n",
    "    #'report_point' : 252,\n",
    "    'reward_function':'sharpe'}\n",
    "\n",
    "train_env = gym.make('PortfolioAllocation-v0', **env_kwargs)\n",
    "train_env = Monitor(train_env, 'monitor')"
   ],
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "check_env(train_env)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "venv, obs = train_env.get_sb_env()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "pmyfRQxy8f33"
   },
   "source": [
    "#{'gamma': 0.9999, 'n_steps': 1, 'lr_schedule': 'constant', 'lr': 0.001, 'ent_coef': 0.1, 'vf_coef': 0, 'max_grad_norm': 5, 'n_lstm': 128, 'activation_fn': 'tanh', 'net_arch': 'medium'}.\n",
    "model_kwargs =   {\n",
    "    'gamma': 0.9999,\n",
    "    'n_steps': 1,\n",
    "    'lr_schedule': 'constant',\n",
    "    'learning_rate': 0.001,\n",
    "    'ent_coef': 0.1,\n",
    "    'vf_coef': 0,\n",
    "    'max_grad_norm': 5,\n",
    "    'policy_kwargs' : dict (\n",
    "        n_lstm=128,\n",
    "        act_fun=nn.tanh,\n",
    "        net_arch=[64, 'lstm', dict(pi=[256, 256], vf=[256, 256])]\n",
    "        )\n",
    "    }\n",
    "\n",
    "a2c_model = A2C(policy = MlpLnLstmPolicy, tensorboard_log=\"tensorboard\",env = venv, **model_kwargs)\n",
    "\n",
    "#a2c_model_default = A2C(policy = MlpLnLstmPolicy, tensorboard_log=\"tensorboard\",env = venv)"
   ],
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "#a2c_model.get_parameter_list()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "#a2c_model_default.get_parameter_list()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2516                 reward: 4.697                 daily_returns: 10.018                 benchmark: 6.731                 index : 18.340                 sharpe: 15.676                 cum. rtns: 891.032                 portf val: 9,910,316.42\n",
      "day: 2516                 reward: 3.932                 daily_returns: 7.565                 benchmark: 4.277                 index : 18.340                 sharpe: 9.037                 cum. rtns: 432.194                 portf val: 5,321,940.58\n",
      "day: 2516                 reward: 1.450                 daily_returns: 5.089                 benchmark: 1.801                 index : 18.340                 sharpe: 4.504                 cum. rtns: 157.828                 portf val: 2,578,276.56\n",
      "day: 2516                 reward: 2.044                 daily_returns: 6.011                 benchmark: 2.724                 index : 18.340                 sharpe: 5.861                 cum. rtns: 74.595                 portf val: 1,745,951.01\n",
      "day: 2516                 reward: 2.634                 daily_returns: 5.862                 benchmark: 2.574                 index : 18.340                 sharpe: 9.761                 cum. rtns: 249.074                 portf val: 3,490,736.52\n",
      "mean_reward:26.83 +/- 12.54\n"
     ]
    }
   ],
   "source": [
    "# Random Agent, before training\n",
    "mean_reward, std_reward = evaluate_policy(a2c_model, venv, n_eval_episodes=5)\n",
    "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "rC1P65268f3-"
   },
   "source": [
    "total_timesteps = 20* (len(venv.venv.envs[0].data.date.unique()))"
   ],
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2516                 reward: 1.913                 daily_returns: 3.803                 benchmark: 0.516                 index : 18.340                 sharpe: 4.836                 cum. rtns: 122.593                 portf val: 2,225,934.75\n",
      "day: 2516                 reward: 1.804                 daily_returns: 5.249                 benchmark: 1.961                 index : 18.340                 sharpe: 6.189                 cum. rtns: 189.435                 portf val: 2,894,345.39\n",
      "day: 2516                 reward: 2.107                 daily_returns: 6.209                 benchmark: 2.922                 index : 18.340                 sharpe: 7.904                 cum. rtns: 237.361                 portf val: 3,373,608.54\n",
      "day: 2516                 reward: 3.049                 daily_returns: 6.425                 benchmark: 3.137                 index : 18.340                 sharpe: 8.403                 cum. rtns: 292.870                 portf val: 3,928,701.05\n",
      "day: 2516                 reward: 0.531                 daily_returns: 3.353                 benchmark: 0.065                 index : 18.340                 sharpe: 4.187                 cum. rtns: 76.123                 portf val: 1,761,234.38\n",
      "day: 2516                 reward: 2.298                 daily_returns: 5.626                 benchmark: 2.339                 index : 18.340                 sharpe: 7.877                 cum. rtns: 232.398                 portf val: 3,323,981.44\n",
      "day: 2516                 reward: 3.563                 daily_returns: 6.495                 benchmark: 3.207                 index : 18.340                 sharpe: 7.820                 cum. rtns: 266.989                 portf val: 3,669,887.11\n",
      "day: 2516                 reward: 2.297                 daily_returns: 5.616                 benchmark: 2.329                 index : 18.340                 sharpe: 5.465                 cum. rtns: 210.201                 portf val: 3,102,009.62\n",
      "day: 2516                 reward: 2.336                 daily_returns: 4.384                 benchmark: 1.097                 index : 18.340                 sharpe: 6.487                 cum. rtns: 146.036                 portf val: 2,460,361.36\n",
      "day: 2516                 reward: 3.065                 daily_returns: 7.591                 benchmark: 4.303                 index : 18.340                 sharpe: 10.902                 cum. rtns: 362.805                 portf val: 4,628,053.95\n",
      "day: 2516                 reward: 2.753                 daily_returns: 6.667                 benchmark: 3.380                 index : 18.340                 sharpe: 11.625                 cum. rtns: 341.205                 portf val: 4,412,054.10\n",
      "day: 2516                 reward: 2.871                 daily_returns: 4.632                 benchmark: 1.345                 index : 18.340                 sharpe: 8.678                 cum. rtns: 168.455                 portf val: 2,684,545.94\n",
      "day: 2516                 reward: -0.739                 daily_returns: -0.337                 benchmark: -3.625                 index : 18.340                 sharpe: -0.986                 cum. rtns: -34.499                 portf val: 655,007.29\n",
      "day: 2516                 reward: -1.709                 daily_returns: -0.849                 benchmark: -4.136                 index : 18.340                 sharpe: -2.646                 cum. rtns: -31.544                 portf val: 684,559.58\n",
      "day: 2516                 reward: 3.044                 daily_returns: 4.361                 benchmark: 1.074                 index : 18.340                 sharpe: 8.603                 cum. rtns: 158.177                 portf val: 2,581,767.09\n",
      "day: 2516                 reward: 2.752                 daily_returns: 4.637                 benchmark: 1.349                 index : 18.340                 sharpe: 7.548                 cum. rtns: 167.222                 portf val: 2,672,221.98\n",
      "day: 2516                 reward: 1.687                 daily_returns: 2.043                 benchmark: -1.244                 index : 18.340                 sharpe: 2.130                 cum. rtns: 36.651                 portf val: 1,366,509.20\n",
      "day: 2516                 reward: 1.940                 daily_returns: 4.538                 benchmark: 1.250                 index : 18.340                 sharpe: 5.664                 cum. rtns: 161.338                 portf val: 2,613,383.30\n",
      "day: 2516                 reward: 1.523                 daily_returns: 2.744                 benchmark: -0.544                 index : 18.340                 sharpe: 3.512                 cum. rtns: 67.289                 portf val: 1,672,887.66\n",
      "day: 2516                 reward: 1.453                 daily_returns: 3.953                 benchmark: 0.666                 index : 18.340                 sharpe: 5.074                 cum. rtns: 139.943                 portf val: 2,399,431.14\n"
     ]
    }
   ],
   "source": [
    "#total_timesteps = 500 * (len(venv.data.date.unique())-1)\n",
    "trained_a2c_model= a2c_model.learn(total_timesteps=total_timesteps, #callback=tbc.TensorBoardCallback(),\n",
    "                                   tb_log_name='A2C_lstm_bmk'+datetime.now().strftime(\"%H-%M\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "trained_a2c_model.save('ac2_mlplnltsm_100_10_t18_random_sharpe.zip')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\kbine\\anaconda3\\envs\\stable2\\lib\\site-packages\\stable_baselines\\common\\tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\kbine\\anaconda3\\envs\\stable2\\lib\\site-packages\\stable_baselines\\common\\tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\kbine\\anaconda3\\envs\\stable2\\lib\\site-packages\\stable_baselines\\common\\policies.py:116: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\kbine\\anaconda3\\envs\\stable2\\lib\\site-packages\\stable_baselines\\common\\input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\kbine\\anaconda3\\envs\\stable2\\lib\\site-packages\\stable_baselines\\common\\policies.py:442: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From C:\\Users\\kbine\\anaconda3\\envs\\stable2\\lib\\site-packages\\stable_baselines\\common\\tf_layers.py:123: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\kbine\\anaconda3\\envs\\stable2\\lib\\site-packages\\stable_baselines\\a2c\\a2c.py:160: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\kbine\\anaconda3\\envs\\stable2\\lib\\site-packages\\tensorflow\\python\\ops\\clip_ops.py:286: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\kbine\\anaconda3\\envs\\stable2\\lib\\site-packages\\stable_baselines\\a2c\\a2c.py:184: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\kbine\\anaconda3\\envs\\stable2\\lib\\site-packages\\tensorflow\\python\\training\\rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\kbine\\anaconda3\\envs\\stable2\\lib\\site-packages\\stable_baselines\\a2c\\a2c.py:196: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#trained_a2c_model =  A2C.load('ac2_mlplnltsm_100_10_t18.zip')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2516                 reward: 1.081                 daily_returns: 4.368                 benchmark: 1.081                 index : 18.340                 sharpe: 4.913                 cum. rtns: 68.759                 portf val: 1,687,590.60\n",
      "day: 2516                 reward: 1.081                 daily_returns: 4.368                 benchmark: 1.081                 index : 18.340                 sharpe: 4.913                 cum. rtns: 68.759                 portf val: 1,687,590.60\n",
      "day: 2516                 reward: 1.081                 daily_returns: 4.368                 benchmark: 1.081                 index : 18.340                 sharpe: 4.913                 cum. rtns: 68.759                 portf val: 1,687,590.60\n",
      "day: 2516                 reward: 1.081                 daily_returns: 4.368                 benchmark: 1.081                 index : 18.340                 sharpe: 4.913                 cum. rtns: 68.759                 portf val: 1,687,590.60\n",
      "day: 2516                 reward: 1.081                 daily_returns: 4.368                 benchmark: 1.081                 index : 18.340                 sharpe: 4.913                 cum. rtns: 68.759                 portf val: 1,687,590.60\n",
      "mean_reward:2.73 +/- 0.02\n"
     ]
    }
   ],
   "source": [
    "mean_reward, std_reward = evaluate_policy(trained_a2c_model, venv, n_eval_episodes=5)\n",
    "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "eval_kwargs = {'filename':'sp500.csv',\n",
    "    'date_from':'2018-01-01',\n",
    "    'date_to':'2020-12-31',\n",
    "    'investment':1000000,\n",
    "    'risk_free_rate': 0.5, # approx US Treasury Note return\n",
    "    'sample_size':10,\n",
    "    'random_sample':False,\n",
    "    'observations' : observations,\n",
    "    'save_info' : True,\n",
    "    #'report_point' : 252,\n",
    "    'reward_function':'sharpe'}\n",
    "\n",
    "eval_env =  gym.make('PortfolioAllocation-v0', **eval_kwargs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "eval_venv, obs = eval_env.get_sb_env()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 653                 reward: 1.780                 daily_returns: 7.322                 benchmark: 2.841                 index : 64.277                 sharpe: 3.266                 cum. rtns: 48.570                 portf val: 1,485,697.19\n",
      "day: 653                 reward: 2.987                 daily_returns: 9.366                 benchmark: 4.885                 index : 64.277                 sharpe: 4.234                 cum. rtns: 68.884                 portf val: 1,688,844.97\n",
      "day: 653                 reward: 3.211                 daily_returns: 9.820                 benchmark: 5.339                 index : 64.277                 sharpe: 4.448                 cum. rtns: 73.977                 portf val: 1,739,767.77\n",
      "day: 653                 reward: 3.226                 daily_returns: 9.842                 benchmark: 5.361                 index : 64.277                 sharpe: 4.464                 cum. rtns: 74.265                 portf val: 1,742,654.27\n",
      "day: 653                 reward: 3.288                 daily_returns: 10.546                 benchmark: 6.065                 index : 64.277                 sharpe: 4.800                 cum. rtns: 82.446                 portf val: 1,824,459.26\n",
      "day: 653                 reward: 3.170                 daily_returns: 9.585                 benchmark: 5.104                 index : 64.277                 sharpe: 4.343                 cum. rtns: 71.338                 portf val: 1,713,379.92\n",
      "day: 653                 reward: 3.229                 daily_returns: 10.197                 benchmark: 5.716                 index : 64.277                 sharpe: 4.630                 cum. rtns: 78.293                 portf val: 1,782,925.87\n",
      "day: 653                 reward: 3.301                 daily_returns: 10.902                 benchmark: 6.421                 index : 64.277                 sharpe: 4.967                 cum. rtns: 86.693                 portf val: 1,866,925.48\n",
      "day: 653                 reward: 3.308                 daily_returns: 11.018                 benchmark: 6.537                 index : 64.277                 sharpe: 5.023                 cum. rtns: 88.103                 portf val: 1,881,030.75\n",
      "day: 653                 reward: 3.314                 daily_returns: 11.081                 benchmark: 6.600                 index : 64.277                 sharpe: 5.051                 cum. rtns: 88.865                 portf val: 1,888,647.38\n",
      "mean_reward:17.16 +/- 8.73\n"
     ]
    }
   ],
   "source": [
    "mean_reward, std_reward = evaluate_policy(trained_a2c_model, eval_venv, n_eval_episodes=10)\n",
    "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}