@article{ABOUSSALAH2020112891,
title = {Continuous control with Stacked Deep Dynamic Recurrent Reinforcement Learning for portfolio optimization},
journal = {Expert Systems with Applications},
volume = {140},
pages = {112891},
year = {2020},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2019.112891},
url = {https://www.sciencedirect.com/science/article/pii/S0957417419306074},
author = {Amine Mohamed Aboussalah and Chi-Guhn Lee},
keywords = {Reinforcement learning, Policy gradient, Deep learning, Sequential model-based optimization, Financial time series, Portfolio management, Trading systems},
abstract = {Recurrent reinforcement learning (RRL) techniques have been used to optimize asset trading systems and have achieved outstanding results. However, the majority of the previous work has been dedicated to systems with discrete action spaces. To address the challenge of continuous action and multi-dimensional state spaces, we propose the so called Stacked Deep Dynamic Recurrent Reinforcement Learning (SDDRRL) architecture to construct a real-time optimal portfolio. The algorithm captures the up-to-date market conditions and rebalances the portfolio accordingly. Under this general vision, Sharpe ratio, which is one of the most widely accepted measures of risk-adjusted returns, has been used as a performance metric. Additionally, the performance of most machine learning algorithms highly depends on their hyperparameter settings. Therefore, we equipped SDDRRL with the ability to find the best possible architecture topology using an automated Gaussian Process (GP) with Expected Improvement (EI) as an acquisition function. This allows us to select the best architectures that maximizes the total return while respecting the cardinality constraints. Finally, our system was trained and tested in an online manner for 20 successive rounds with data for ten selected stocks from different sectors of the S&P 500 from January 1st, 2013 to July 31st, 2017. The experiments reveal that the proposed SDDRRL achieves superior performance compared to three benchmarks: the rolling horizon Mean-Variance Optimization (MVO) model, the rolling horizon risk parity model, and the uniform buy-and-hold (UBAH) index.}
}
@article{ALMAHDI2017267,
title = {An adaptive portfolio trading system: A risk-return portfolio optimization using recurrent reinforcement learning with expected maximum drawdown},
journal = {Expert Systems with Applications},
volume = {87},
pages = {267-279},
year = {2017},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2017.06.023},
url = {https://www.sciencedirect.com/science/article/pii/S0957417417304402},
author = {Saud Almahdi and Steve Y. Yang},
keywords = {Recurrent reinforcement learning, Expected maximum drawdown, Optimal portfolio rebalancing, Downside risk},
abstract = {Dynamic control theory has long been used in solving optimal asset allocation problems, and a number of trading decision systems based on reinforcement learning methods have been applied in asset allocation and portfolio rebalancing. In this paper, we extend the existing work in recurrent reinforcement learning (RRL) and build an optimal variable weight portfolio allocation under a coherent downside risk measure, the expected maximum drawdown, E(MDD). In particular, we propose a recurrent reinforcement learning method, with a coherent risk adjusted performance objective function, the Calmar ratio, to obtain both buy and sell signals and asset allocation weights. Using a portfolio consisting of the most frequently traded exchange-traded funds, we show that the expected maximum drawdown risk based objective function yields superior return performance compared to previously proposed RRL objective functions (i.e. the Sharpe ratio and the Sterling ratio), and that variable weight RRL long/short portfolios outperform equal weight RRL long/short portfolios under different transaction cost scenarios. We further propose an adaptive E(MDD) risk based RRL portfolio rebalancing decision system with a transaction cost and market condition stop-loss retraining mechanism, and we show that the proposed portfolio trading system responds to transaction cost effects better and outperforms hedge fund benchmarks consistently.}
}
@book{BakerH.Kent2013PTaM,
publisher = {Oxford University Press},
isbn = {9780199829699},
year = {2013},
title = {Portfolio Theory and Management},
language = {eng},
address = {New York},
author = {Baker, H. Kent and Filbeck, Greg},
keywords = {Asset Pricing ; Financial Markets ; Investment analysis ; Investments ; Portfolio management},
abstract = {The world of portfolio management has expanded greatly over the past three decades, and along with it, so have the theoretical tools necessary to appropriately service the needs of both private wealth and institutional clients. While the foundations of modern finance emerged during the 1950s and asset pricing models were developed in a portfolio context in the 1960s, portfolio management has now expanded into more complex models. Further, the traditional assumption of rational investor behavior with decisions made on the basis of statistical distributions has expanded to consider behavioral attributes of clients as well as goals-based strategies. Performance assessment has taken on greater importance since the 1990s. Portfolio management today emerges as a dynamic process that continues to evolve at a rapid pace. This 30-chapter book takes readers through the foundations of portfolio management with the contributions of financial pioneers up to the latest trends. Portfolio Theory and Management provides a comprehensive discussion of portfolio theory, empirical work, and practice. It not only attempts to blend the conceptual world of scholars with the pragmatic view of practitioners, but it also synthesizes important and relevant research studies in a succinct and clear manner including recent developments. Chapters are grouped into seven broad categories of interest: (1) portfolio theory and asset pricing, (2) the investment policy statement and fiduciary duties, (3) asset allocation and portfolio construction, (4) risk management, (5) portfolio execution, monitoring, and rebalancing, (6) evaluating and reporting portfolio performance, and (7) special topics.},
}
@article{GomberPeter2018OtFR,
journal = {Journal of management information systems},
pages = {220--265},
volume = {35},
number = {1},
year = {2018},
title = {On the Fintech Revolution: Interpreting the Forces of Innovation, Disruption, and Transformation in Financial Services},
copyright = {Copyright 2018 Elsevier B.V., All rights reserved.},
language = {eng},
author = {Gomber, Peter and Kauffman, Robert J and Parker, Chris and Weber, Bruce W},
issn = {0742-1222},
}
@article{JiangZhengyao2017ADRL,
year = {2017},
title = {A Deep Reinforcement Learning Framework for the Financial Portfolio Management Problem},
copyright = {http://arxiv.org/licenses/nonexclusive-distrib/1.0},
language = {eng},
author = {Jiang, Zhengyao and Xu, Dixing and Liang, Jinjun},
abstract = {Financial portfolio management is the process of constant redistribution of a
fund into different financial products. This paper presents a
financial-model-free Reinforcement Learning framework to provide a deep machine
learning solution to the portfolio management problem. The framework consists
of the Ensemble of Identical Independent Evaluators (EIIE) topology, a
Portfolio-Vector Memory (PVM), an Online Stochastic Batch Learning (OSBL)
scheme, and a fully exploiting and explicit reward function. This framework is
realized in three instants in this work with a Convolutional Neural Network
(CNN), a basic Recurrent Neural Network (RNN), and a Long Short-Term Memory
(LSTM). They are, along with a number of recently reviewed or published
portfolio-selection strategies, examined in three back-test experiments with a
trading period of 30 minutes in a cryptocurrency market. Cryptocurrencies are
electronic and decentralized alternatives to government-issued money, with
Bitcoin as the best-known example of a cryptocurrency. All three instances of
the framework monopolize the top three positions in all experiments,
outdistancing other compared trading algorithms. Although with a high
commission rate of 0.25% in the backtests, the framework is able to achieve at
least 4-fold returns in 50 days.},
}
@article{KellyJ1956Anio,
journal = {I.R.E. transactions on information theory},
pages = {185--189},
volume = {2},
publisher = {The Institute of Radio Engineers, Inc},
number = {3},
year = {1956},
title = {A new interpretation of information rate},
copyright = {Copyright 2015 Elsevier B.V., All rights reserved.},
language = {eng},
author = {Kelly, J},
keywords = {Communication channels ; Communication systems ; Cost function ; Humans ; Information rates ; Laboratories ; Probability ; State estimation ; Telephony ; Transducers},
issn = {0096-1000},
abstract = {If the input symbols to a communication channel represent the outcomes of a chance event on which bets are available at odds consistent with their probabilities (i.e., "fair" odds), a gambler can use the knowledge given him by the received symbols to cause his money to grow exponentially. The maximum exponential rate of growth of the gambler's capital is equal to the rate of transmission of information over the channel. This result is generalized to include the case of arbitrary odds. Thus we find a situation in which the transmission rate has significance even though no coding is contemplated. Previously this quantity was given significance only by a theorem of Shannon's which asserted that, with suitable encoding, binary digits could be transmitted over the channel at this rate with an arbitrarily small probability of error.},
}
@book{LiBin2016OPSP,
publisher = {CRC Press},
booktitle = {Online Portfolio Selection},
isbn = {9781138894105},
year = {2016},
title = {Online Portfolio Selection: Principles and Algorithms},
copyright = {2016 by Taylor & Francis Group, LLC},
language = {eng},
address = {Boca Raton},
author = {Li, Bin and Hoi, Steven Chu Hong},
keywords = {BUSINESSnetBASE ; COMPUTERSCIENCEnetBASE ; Finance ; Finance & Economics ; INFORMATIONSCIENCEnetBASE ; Machine Learning ; Machine-learning techniques in finance ; MANAGEMENTnetBASE ; Online portfolio selection (OLPS) ; Optimal portfolio allocation ; Portfolio selection ; SCI-TECHnetBASE ; Statistics for Business ; Statistics for Business, Finance & Economics ; STATSnetBASE ; STMnetBASE},
abstract = {With the aim to sequentially determine optimal allocations across a set of assets, Online Portfolio Selection (OLPS) has significantly reshaped the financial investment landscape. Online Portfolio Selection: Principles and Algorithms supplies a comprehensive survey of existing OLPS principles and presents a collection of innovative strategies that leverage machine learning techniques for financial investment.The book presents four new algorithms based on machine learning techniques that were designed by the authors, as well as a new back-test system they developed for evaluating trading strategy effectiveness. The book uses simulations with real market data to illustrate the trading strategies in action and to provide readers with the confidence to deploy the strategies themselves. The book is presented in five sections that:
Introduce OLPS and formulate OLPS as a sequential decision task
Present key OLPS principles, including benchmarks, follow the winner, follow the loser, pattern matching, and meta-learning
Detail four innovative OLPS algorithms based on cutting-edge machine learning techniques
Provide a toolbox for evaluating the OLPS algorithms and present empirical studies comparing the proposed algorithms with the state of the art
Investigate possible future directions
Complete with a back-test system that uses historical data to evaluate the performance of trading strategies, as well as MATLAB® code for the back-test systems, this book is an ideal resource for graduate students in finance, computer science, and statistics. It is also suitable for researchers and engineers interested in computational investment.Readers are encouraged to visit the authors’ website for updates: http://olps.stevenhoi.org.},
}
@article{LiBin2014OpsA,
journal = {ACM computing surveys},
pages = {1--36},
volume = {46},
publisher = {ACM},
number = {3},
year = {2014},
title = {Online portfolio selection: A survey},
copyright = {Copyright 2014 Elsevier B.V., All rights reserved.},
language = {eng},
author = {Li, Bin and Hoi, Steven C. H},
keywords = {Algorithms ; Data mining ; Machine learning ; Optimization ; Portfolio selection ; Surveys},
issn = {0360-0300},
abstract = {Online portfolio selection is a fundamental problem in computational finance, which has been extensively studied across several research communities, including finance, statistics, artificial intelligence, machine learning, and data mining. This article aims to provide a comprehensive survey and a structural understanding of online portfolio selection techniques published in the literature. From an online machine learning perspective, we first formulate online portfolio selection as a sequential decision problem, and then we survey a variety of state-of-the-art approaches, which are grouped into several major categories, including benchmarks, Follow-the-Winner approaches, Follow-the-Loser approaches, Pattern-Matching--based approaches, and Meta-Learning Algorithms. In addition to the problem formulation and related algorithms, we also discuss the relationship of these algorithms with the capital growth theory so as to better understand the similarities and differences of their underlying trading ideas. This article aims to provide a timely and comprehensive survey for both machine learning and data mining researchers in academia and quantitative portfolio managers in the financial industry to help them understand the state of the art and facilitate their research and practical applications. We also discuss some open issues and evaluate some emerging new trends for future research.},
}
@article{MarkowitzHarry1952PS,
journal = {The Journal of finance (New York)},
pages = {77},
volume = {7},
number = {1},
year = {1952},
title = {Portfolio Selection},
language = {eng},
author = {Markowitz, Harry},
issn = {0022-1082},
}
@article{FrancoModigliani1958TCoC,
journal = {The American economic review},
pages = {261--297},
volume = {48},
publisher = {The American Economic Association},
number = {3},
year = {1958},
title = {The Cost of Capital, Corporation Finance and the Theory of Investment},
copyright = {Coppyright 1958 American Economic Association},
language = {eng},
author = {Franco Modigliani and Merton H. Miller},
keywords = {Business structures ; Capital costs ; Capital investments ; Capital structure ; Common stock ; Financial investments ; Financial leverage ; Investment return rates ; Stock shares ; Yield},
issn = {0002-8282},
}
@article{MoodyJ2001Lttv,
journal = {IEEE transactions on neural networks},
pages = {875--889},
volume = {12},
publisher = {IEEE},
number = {4},
year = {2001},
title = {Learning to trade via direct reinforcement},
copyright = {Copyright 2008 Elsevier B.V., All rights reserved.},
language = {eng},
address = {PISCATAWAY},
author = {Moody, J and Saffell, M},
keywords = {Adaptive algorithm ; Algorithms ; Analysis ; Asset management ; Computer Science ; Computer Science, Artificial Intelligence ; Computer Science, Hardware & Architecture ; Computer Science, Theory & Methods ; Decision making ; Differential Sharpe ratio ; Direct reinforcement (DR) ; Downside deviation ; Dynamic programming ; Engineering ; Engineering, Electrical & Electronic ; Investments ; Learning ; Optimization methods ; Policy gradient ; Portfolios ; Predictive models ; Q-learning ; Recurrent reinforcement learning ; Reinforcement (Psychology) ; Research ; Risk ; Science & Technology ; Stochastic analysis ; Stochastic processes ; TD-learning ; Technology ; Trading ; Value function},
issn = {1045-9227},
abstract = {We present methods for optimizing portfolios, asset allocations, and trading systems based on direct reinforcement (DR). In this approach, investment decision-making is viewed as a stochastic control problem, and strategies are discovered directly. We present an adaptive algorithm called recurrent reinforcement learning (RRL) for discovering investment policies. The need to build forecasting models is eliminated, and better trading performance is obtained. The direct reinforcement approach differs from dynamic programming and reinforcement algorithms such as TD-learning and Q-learning, which attempt to estimate a value function for the control problem. We find that the RRL direct reinforcement framework enables a simpler problem representation, avoids Bellman's curse of dimensionality and offers compelling advantages in efficiency. We demonstrate how direct reinforcement can be used to optimize risk-adjusted investment returns (including the differential Sharpe ratio), while accounting for the effects of transaction costs. In extensive simulation work using real financial data, we find that our approach based on RRL produces better trading strategies than systems utilizing Q-learning (a value function method). Real-world applications include an intra-daily currency trader and a monthly asset allocation system for the S&P 500 Stock Index and T-Bills.},
}

@article{MoodyJohn1998Pfar,
journal = {Journal of forecasting},
pages = {441--470},
volume = {17},
publisher = {John Wiley & Sons, Ltd},
number = {5-6},
year = {1998},
title = {Performance functions and reinforcement learning for trading systems and portfolios},
copyright = {Copyright © 1998 John Wiley & Sons, Ltd.},
language = {eng},
address = {Chichester},
author = {Moody, John and Wu, Lizhong and Liao, Yuansong and Saffell, Matthew},
keywords = {Asset allocation ; Bernoulli utility ; Differential sharpe ratio ; Dynamic programming ; Investments ; Management ; Methods ; On-line learning ; performance functions ; Portfolio management ; Portfolio optimization ; recurrence ; Recurrent reinforcement learning ; Recursive updating ; Reinforcement learning ; Research ; State dependence ; Stocks ; Trading systems ; Transactions costs},
issn = {0277-6693},
abstract = {We propose to train trading systems and portfolios by optimizing objective functions that directly measure trading and investment performance. Rather than basing a trading system on forecasts or training via a supervised learning algorithm using labelled trading data, we train our systems using recurrent reinforcement learning (RRL) algorithms. The performance functions that we consider for reinforcement learning are profit or wealth, economic utility, the Sharpe ratio and our proposed differential Sharpe ratio. The trading and portfolio management systems require prior decisions as input in order to properly take into account the effects of transactions costs, market impact, and taxes. This temporal dependence on system state requires the use of reinforcement versions of standard recurrent learning algorithms. We present empirical results in controlled experiments that demonstrate the efficacy of some of our methods for optimizing trading systems and portfolios. For a long/short trader, we find that maximizing the differential Sharpe ratio yields more consistent results than maximizing profits, and that both methods outperform a trading system based on forecasts that minimize MSE. We find that portfolio traders trained to maximize the differential Sharpe ratio achieve better risk‐adjusted returns than those trained to maximize profit. Finally, we provide simulation results for an S&P 500/TBill asset allocation system that demonstrate the presence of out‐of‐sample predictability in the monthly S&P 500 stock index for the 25 year period 1970 through 1994. Copyright © 1998 John Wiley & Sons, Ltd.},
}


@article{SharpeWilliamF1964CAPA,
journal = {The Journal of finance (New York)},
pages = {425--442},
volume = {19},
publisher = {Blackwell Publishing Ltd},
number = {3},
year = {1964},
title = {CAPITAL ASSET PRICES: A THEORY OF MARKET EQUILIBRIUM UNDER CONDITIONS OF RISK},
copyright = {Copyright 1964 American Finance Association},
language = {eng},
address = {Oxford, UK},
author = {Sharpe, William F},
keywords = {Capital assets ; Capital markets ; Expected returns ; Financial investments ; Investment plans ; Investment return rates ; Investment risk ; Investors ; Market conditions ; Pure rates of interest},
issn = {0022-1082},
}
@article {Sharpe94,
	author = {Sharpe, William F.},
	title = {The Sharpe Ratio},
	volume = {21},
	number = {1},
	pages = {49--58},
	year = {1994},
	doi = {10.3905/jpm.1994.409501},
	publisher = {Institutional Investor Journals Umbrella},
	issn = {0095-4918},
	URL = {https://jpm.pm-research.com/content/21/1/49},
	eprint = {https://jpm.pm-research.com/content/21/1/49.full.pdf},
	journal = {The Journal of Portfolio Management}
}
@article{finrl2020,
    author  = {Liu, Xiao-Yang and Yang, Hongyang and Chen, Qian and Zhang, Runjia and Yang, Liuqing and Xiao, Bowen and Wang, Christina Dan},
    journal = {Deep RL Workshop, NeurIPS 2020},
    title   = {FinRL: A Deep Reinforcement Learning Library for Automated Stock Trading in Quantitative Finance},
    url     = {https://arxiv.org/pdf/2011.09607.pdf},
    year    = {2020}
}

@misc{stable-baselines,
  author = {Hill, Ashley and Raffin, Antonin and Ernestus, Maximilian and Gleave, Adam and Kanervisto, Anssi and Traore, Rene and Dhariwal, Prafulla and Hesse, Christopher and Klimov, Oleg and Nichol, Alex and Plappert, Matthias and Radford, Alec and Schulman, John and Sidor, Szymon and Wu, Yuhuai},
  title = {Stable Baselines},
  year = {2018},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/hill-a/stable-baselines}},
}
@article{Akiba_2019,
   title={Optuna},
   ISBN={9781450362016},
   url={http://dx.doi.org/10.1145/3292500.3330701},
   DOI={10.1145/3292500.3330701},
   journal={Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining},
   publisher={ACM},
   author={Akiba, Takuya and Sano, Shotaro and Yanase, Toshihiko and Ohta, Takeru and Koyama, Masanori},
   year={2019},
   month={Jul}
}
@misc{rl-zoo,
  author = {Raffin, Antonin},
  title = {RL Baselines Zoo},
  year = {2018},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/araffin/rl-baselines-zoo}},
}
@misc{ta-lib,
  author = {Padial, Darío López},
  title = {Technical Analysis Library in Python},
  year = {2018},
  publisher = {GitHub},
  journal = {GitHub repository},   
  howpublished = {\url{https://github.com/bukosabino/ta}},
}

@misc{mnih2016asynchronous,
      title={Asynchronous Methods for Deep Reinforcement Learning}, 
      author={Volodymyr Mnih and Adrià Puigdomènech Badia and Mehdi Mirza and Alex Graves and Timothy P. Lillicrap and Tim Harley and David Silver and Koray Kavukcuoglu},
      year={2016},
      eprint={1602.01783},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@article{Hochreiter1997,
author = {Hochreiter, Sepp and Schmidhuber, Jürgen},
year = {1997},
month = {12},
pages = {1735-80},
title = {Long Short-term Memory},
volume = {9},
journal = {Neural computation},
doi = {10.1162/neco.1997.9.8.1735}

}
@incollection{PES90,
  author      = "Persaran, M. Hashem",
  title       = "Econometrics",
  editor      = "Eatwell, John and Milgate, Murray and Newman, Peter",
  booktitle   = "The New Palgrave: Econometrics",
  publisher   = "The MacMillan Press Limited",
  address     = "London",
  year        = 1990,
  pages       = "1-34",
  chapter     = 1,
}
@book{SuttonRichardS.2018Rl:a,
publisher = {The MIT Press},
isbn = {0-262-35270-2},
year = {2018},
title = {Reinforcement learning : an introduction},
edition = {Second edition.},
language = {eng},
address = {Cambridge, Massachusetts},
author = {Sutton, Richard S.},
keywords = {Reinforcement learning; Electronic books},
series = {Adaptive computation and machine learning series},
abstract = {"Reinforcement learning, one of the most active research areas in artificial intelligence, is a computational approach to learning whereby an agent tries to maximize the total amount of reward it receives while interacting with a complex, uncertain environment. In Reinforcement Learning, Richard Sutton and Andrew Barto provide a clear and simple account of the field's key ideas and algorithms."--},
}
@book{LapanMaxim2020Drlh,
publisher = {Packt Publishing},
isbn = {9781838820046},
year = {2020},
edition = {Second edition.},
title = {Deep reinforcement learning hands-on apply modern RL methods, with deep Q-networks, value iteration, policy gradients, TRPO, AlphaGo Zero and more},
language = {eng},
address = {Birmingham, England},
author = {Lapan, Maxim},
keywords = {Reinforcement learning; Electronic books},
}
@book{DixonMatthewF2020MLiF,
publisher = {Springer International Publishing AG},
booktitle = {Machine Learning in Finance},
isbn = {9783030410674},
year = {2020},
title = {Machine Learning in Finance: From Theory to Practice},
copyright = {Springer Nature Switzerland AG 2020},
language = {eng},
address = {Cham},
author = {Dixon, Matthew F and Halperin, Igor and Bilokon, Paul}
}

@book{CholletF2018DlwP,
publisher = {Manning},
isbn = {9781617294433},
year = {2018},
title = {Deep learning with Python},
language = {eng},
address = {Shelter Island},
author = {Chollet, François},
keywords = {Machine learning; Python (Computer program language)},
}

@book{GoodfellowIan2016Dl,
publisher = {The MIT Press},
isbn = {9780262035613},
year = {2016},
title = {Deep learning},
language = {eng},
address = {Cambridge, Massachusetts},
author = {Goodfellow, Ian},
keywords = {Machine learning,},
lccn = {2016022992},
series = {Adaptive computation and machine learning},
}
@book{dePradoMarcos2018AiFM,
publisher = {Wiley},
isbn = {1-119-48211-9},
year = {2018},
title = {Advances in Financial Machine Learning},
edition = {1st edition.},
language = {eng},
author = {de Prado, Marcos},
keywords = {Electronic books},
abstract = {Machine learning (ML) is changing virtually every aspect of our lives. Today ML algorithms accomplish tasks that until recently only expert humans could perform. As it relates to finance, this is the most exciting time to adopt a disruptive technology that will transform how everyone invests for generations. Readers will learn how to structure Big data in a way that is amenable to ML algorithms; how to conduct research with ML algorithms on that data; how to use supercomputing methods; how to backtest your discoveries while avoiding false positives. The book addresses real-life problems faced by practitioners on a daily basis, and explains scientifically sound solutions using math, supported by code and examples. Readers become active users who can test the proposed solutions in their particular setting. Written by a recognized expert and portfolio manager, this book will equip investment professionals with the groundbreaking tools needed to succeed in modern finance.},
}
@article{BaileyDavidH2012Tsre,
journal = {The journal of risk},
pages = {3--44},
volume = {15},
publisher = {INCISIVE MEDIA},
number = {2},
year = {2012},
title = {The sharpe ratio efficient frontier},
copyright = {Copyright 2017 Elsevier B.V., All rights reserved.},
language = {eng},
address = {LONDON},
author = {Bailey, David H and de Prado, Marcos López},
keywords = {Business & Economics ; Business, Finance ; Social Sciences},
issn = {1465-1211},
abstract = {We evaluate the probability that an estimated Sharpe ratio will exceed a given threshold in the presence of nonnormal returns. We show that this new uncertainty-adjusted investment skill metric (called the probabilistic Sharpe ratio) has a number of important applications. First, it allows us to establish the track-record length needed for rejecting the hypothesis that a measured Sharpe ratio is below a certain threshold with a given confidence level. Second, it models the trade-off between track-record length and undesirable statistical features (eg, negative skewness with positive excess kurtosis). Third, it explains why track records with those undesirable traits would benefit from reporting performance with the highest sampling frequency such that the independent and identically distributed assumption is not violated. Fourth, it permits the computation of what we call the Sharpe ratio efficient frontier, which lets us optimize a portfolio under nonnormal, leveraged returns while incorporating the uncertainty derived from track-record length. Results can be validated using the Python code in the appendixes.},
}
@misc{stable-baselines3,
  author = {Raffin, Antonin and Hill, Ashley and Ernestus, Maximilian and Gleave, Adam and Kanervisto, Anssi and Dormann, Noah},
  title = {Stable Baselines3},
  year = {2019},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/DLR-RM/stable-baselines3}},
}
@misc{dixon2020glearner,
      title={G-Learner and GIRL: Goal Based Wealth Management with Reinforcement Learning}, 
      author={Matthew Dixon and Igor Halperin},
      year={2020},
      eprint={2002.10990},
      archivePrefix={arXiv},
      primaryClass={q-fin.PM}
}
@misc{SP500Overview,
    title={S&P 500 Overview},
    author={Global, S&P},
    year={2020},
    howpublished ={\url{https://www.spglobal.com/spdji/en/indices/equity/sp-500/#overview}},
    note={Accessed: 2021-08-08},
}
