{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import PortfolioAllocationGym\n",
        "import numpy as np\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "from stable_baselines3.common.env_checker import check_env\n",
        "import pandas as pd\n",
        "pd.options.mode.chained_assignment = None  # default='warn'"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "id": "UMwfnZQ48f3n",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1628675770654,
          "user_tz": -60,
          "elapsed": 523,
          "user": {
            "displayName": "Keith Bines",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh-1rHYFN7Yxp7RK0dmcaDIhb3bISQHVPcOLlyYAA=s64",
            "userId": "04847342589282886972"
          }
        },
        "gather": {
          "logged": 1629736750321
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env_kwargs = {'filename':'sp500.csv',\n",
        "    'date_from':'2008-01-01',\n",
        "    'date_to':'2017-12-31',\n",
        "    'investment':1000000,\n",
        "    'risk_free_rate': 0.5, # approx US Treasury Note return\n",
        "    'sample_size':100,\n",
        "    'random_sample':False,\n",
        "    'reward_function':'portfolio_value'}\n",
        "\n",
        "train_env = gym.make('PortfolioAllocation-v0', **env_kwargs)"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Au1mKD618f3w",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1628675850134,
          "user_tz": -60,
          "elapsed": 9939,
          "user": {
            "displayName": "Keith Bines",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh-1rHYFN7Yxp7RK0dmcaDIhb3bISQHVPcOLlyYAA=s64",
            "userId": "04847342589282886972"
          }
        },
        "gather": {
          "logged": 1629730801719
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "check_env(train_env)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%%\n"
        },
        "gather": {
          "logged": 1629730802028
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "venv, obs = train_env.get_sb_env()"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%%\n"
        },
        "gather": {
          "logged": 1629730844525
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3 import A2C\n",
        "from stable_baselines3.a2c import MlpPolicy"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "4cLMqQlb8f30",
        "gather": {
          "logged": 1629730847373
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Parameters from hyper tune @ Users/kbines/rl-baselines3-zoo/ac2_50_pv_normalized2\n",
        "model_kwargs =   {'gamma': 0.98,\n",
        "    'normalize_advantage': False,\n",
        "    'max_grad_norm': 1,\n",
        "    'use_rms_prop': False,\n",
        "    'gae_lambda': 1.0,\n",
        "    'n_steps': 5,\n",
        "    'learning_rate': 0.006091038442400068,\n",
        "    'ent_coef': 4.071869686147734e-06,\n",
        "    'vf_coef': 0.36340337458493177,\n",
        "    'policy_kwargs': dict(\n",
        "        log_std_init=0.5523434134392059,\n",
        "        ortho_init= True,\n",
        "        activation_fn=torch.nn.modules.activation.Tanh,\n",
        "        net_arch=[dict(pi=[256,256], vf=[256,256])])\n",
        "    }\n",
        "a2c_model = A2C(policy = MlpPolicy,\n",
        "                env = venv,\n",
        "                **model_kwargs)\n"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "pmyfRQxy8f33",
        "gather": {
          "logged": 1629730855107
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PortfolioAllocationGym.callbacks import TensorBoardCallback as tbc\n",
        "from datetime import datetime"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "1QwoU6Fu8f36",
        "gather": {
          "logged": 1629730858937
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_env.data.head()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1629730935910
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Agent, before training\n",
        "mean_reward, std_reward = evaluate_policy(a2c_model, venv, n_eval_episodes=5)\n",
        "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%%\n"
        },
        "gather": {
          "logged": 1629730897754
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_timesteps = 2 * (len(venv.venv.envs[0].data.date.unique())-1)\n",
        "#total_timesteps = 2 * (len(train_env.data.date.unique())-1)\n",
        "trained_a2c_model= a2c_model.learn(total_timesteps=total_timesteps,\n",
        "                                   tb_log_name='A2C'+datetime.now().strftime(\"%H-%M\"))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "rC1P65268f3-",
        "gather": {
          "logged": 1629730298975
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean_reward, std_reward = evaluate_policy(trained_a2c_model, venv, n_eval_episodes=5)\n",
        "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "\n",
        "eval_kwargs = {'filename':'sp500.csv',\n",
        "    'date_from':'2018-01-01',\n",
        "    'date_to':'2020-12-31',\n",
        "    'investment':1000000,\n",
        "    'risk_free_rate': 0.5,\n",
        "    'reward_function':'daily_returns'}\n",
        "\n",
        "eval_env =  Monitor(gym.make('PortfolioAllocation-v0', **eval_kwargs))\n",
        "\n",
        "mean_reward, std_reward = evaluate_policy(trained_a2c_model, eval_env, n_eval_episodes=10)\n",
        "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")\n",
        "'''"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trained_a2c_model.save('sp500_08_17_opt_49')\n",
        "\n",
        "\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 39,
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%%\n"
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "azureml_py38_pytorch",
      "language": "python",
      "display_name": "Python 3.8 - PyTorch"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.1",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "Example.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "kernel_info": {
      "name": "azureml_py38_pytorch"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}